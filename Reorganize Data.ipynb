{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reorganizing player data.\n",
    "The object of this code is to organize the data into the following for machine learning:  \n",
    "\n",
    "Inputs :   \n",
    "    The differences between (averaged) stats of competing players for a specific pair of teams.  \n",
    "    For example, if the game is Team1 vs Team2, and Team1 will play 5 players who (on average) score [20,15,13,12,11], and Team2 will play 7 players who (on average) score [12,10,11,13,14,9,5], then the SCORE stat will be $\\frac{1}{5}\\left(20+15+13+12+11\\right) - \\frac{1}{7}\\left(12+10+11+13+14+9+5\\right) \\approx 3.62857$.  \n",
    "\n",
    "Output :  \n",
    "    Target value will be the score margin (so if Team1 scored 67 points and Team2 score 73, the margin would be -6)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, we load in data to select players who will play\n",
    "path = './DATA/'\n",
    "\n",
    "train = []\n",
    "test = []\n",
    "# We'll also save players names as we go\n",
    "players_train = []\n",
    "players_test = []\n",
    "\n",
    "# Walk through player files\n",
    "for dir_path , dir_name , file_names in os.walk(path) :\n",
    "    # 2017 will be our testing set\n",
    "    if '2017' in dir_path :\n",
    "        for name in file_names :\n",
    "            # Grab avgs file\n",
    "            if name[-4:] == 'avgs' :\n",
    "                data = pd.read_csv(os.path.join(dir_path,name))\n",
    "                # This puts the players name in order of their row in the training matrix\n",
    "                for i in range(data.shape[0]) :\n",
    "                    players_test.append(data.iloc[i,0])\n",
    "                data = data.drop(['Unnamed: 0'],axis=1)\n",
    "                if isinstance(test,list) :\n",
    "                    test = data.as_matrix()\n",
    "                else :\n",
    "                    test = np.vstack((test,data))\n",
    "    # Everything else will become our training set\n",
    "    elif '2018' not in dir_path :\n",
    "        for name in file_names :\n",
    "            # Grab avgs file\n",
    "            if name[-4:] == 'avgs' :\n",
    "                data = pd.read_csv(os.path.join(dir_path,name))\n",
    "                # This puts the players name in order of their row in the training matrix\n",
    "                for i in range(data.shape[0]) :\n",
    "                    players_train.append(data.iloc[i,0])\n",
    "                data = data.drop(['Unnamed: 0'],axis=1)\n",
    "                if isinstance(train,list) :\n",
    "                    train = data.as_matrix()\n",
    "                else :\n",
    "                    train = np.vstack((train,data.as_matrix()))\n",
    "\n",
    "# From the way the data is saved, the last column is whether or not the player\n",
    "#     is considered a major contributor during the season.\n",
    "train_x = train[:,1:3]\n",
    "train_y = train[:,-1]\n",
    "test_x = test[:,1:3]\n",
    "test_y = test[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Correctly Identified Players: 0.8671875\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(train_x,train_y)\n",
    "res = lr.predict(test_x)\n",
    "print('% Correctly Identified Players: '+str(lr.score(test_x,test_y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of players predicted to sit on the bench: 297\n"
     ]
    }
   ],
   "source": [
    "playing = list(np.array(players_test)[res == 1])\n",
    "print('# of players predicted to sit on the bench: '+str(len(players_test)-len(playing)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Played, predicted they sat: 36\n",
      "Sat, predicted they played: 66\n",
      "Total numb. of predictions: 768\n",
      "False Negative Rate       : 0.046875\n",
      "True Positive Rate        : 0.52734375\n"
     ]
    }
   ],
   "source": [
    "false_acc = np.array(test_y - res)\n",
    "true_acc = np.array(test_y + res)\n",
    "num_preds = len(res)\n",
    "TP = sum(true_acc == 2)\n",
    "TN = sum(true_acc == 0)\n",
    "FN = sum(false_acc == 1)\n",
    "FP = sum(false_acc == -1)\n",
    "print('Played, predicted they sat: {}'.format(FN))\n",
    "print('Sat, predicted they played: {}'.format(FP))\n",
    "print('Total numb. of predictions: {}'.format(num_preds))\n",
    "print('False Negative Rate       : {}'.format(FN/num_preds))\n",
    "print('True Positive Rate        : {}'.format(TP/num_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CAN'T GET THIS TO WORK\n",
    "# Filter out non-contributors\n",
    "#new_players_train = [players_train[i] for i in range(len(train_y)) if train_y[i] == 1]\n",
    "#new_players_test = [players_test[i] for i in range(len(res)) if res[i] == 1]\n",
    "#players_train = new_players_train\n",
    "#players_test = new_players_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is to condense each team into a single row of statistics\n",
    "cols = ['MP','ORtg','%Ps','Pts','OR','DR','A','TO','Blk','Stl','PF','2Pt %','3Pt %','FT %','2Pt %Att','3Pt %Att','FT %Att','Pnts-Prev','Marg']\n",
    "# Collect yearly avgs dataframes for further use\n",
    "yearly_avgs = []\n",
    "final_data = []\n",
    "final_teams = []\n",
    "# Walk through player files\n",
    "for dir_path , dir_name , file_names in os.walk(path) :\n",
    "    if dir_path[-4:] in ['2013','2014','2015','2016','2017'] :\n",
    "        year = dir_path[-4:]\n",
    "    for name in file_names :\n",
    "        # Grab avgs file\n",
    "        if name[-4:] == 'avgs' and '2018' not in dir_path :\n",
    "            team_name = dir_path[12:]\n",
    "            final_teams.append(team_name+' '+year)\n",
    "            data = pd.read_csv(os.path.join(dir_path,name))\n",
    "            # This averages player's contribution to the team\n",
    "            total = np.zeros((1,train.shape[1]-1))\n",
    "            # Count how many people will be playing\n",
    "            num_players = 0\n",
    "            for i in range(data.shape[0]) :\n",
    "                # Get the player name\n",
    "                pl_name = (data.iloc[i,0])\n",
    "                # If playing, append to final_data\n",
    "                if pl_name in players_train :\n",
    "                    ind = players_train.index(pl_name)\n",
    "                    total += train[ind,:-1]\n",
    "                    num_players = num_players + 1\n",
    "            # If there weren't 5 players picked, grab everyone\n",
    "            if num_players < 5 :\n",
    "                for i in range(data.shape[0]) :\n",
    "                    # Get the player name\n",
    "                    pl_name = (data.iloc[i,0])\n",
    "                    ind = players_test.index(pl_name)\n",
    "                    total += train[ind,:-1]\n",
    "                    num_players = num_players + 1\n",
    "            # Divide by num_players to finish average\n",
    "            total /= num_players\n",
    "            total = total[0]\n",
    "            # Add to final_data\n",
    "            if isinstance(final_data,list) :\n",
    "                final_data = np.array(total)\n",
    "            else :\n",
    "                final_data = np.vstack((final_data,total))\n",
    "    if not isinstance(final_data,list) and final_data.shape[0] == 68 :\n",
    "        # Save it to a csv file\n",
    "        final = pd.DataFrame(data=final_data,columns=cols,index=final_teams)\n",
    "        yearly_avgs.append(final)\n",
    "        final.to_csv('Data_2/All_avgs_'+year+'.csv')\n",
    "        final_data = []\n",
    "        final_teams = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n",
      "(49,)\n"
     ]
    }
   ],
   "source": [
    "sc_rows = ['Adj. Efficiency','Adj. Tempo','Avg. Poss. Length','Effective FG%:','Turnover %:','Off. Reb. %:','FTA/FGA:','3P%:','2P%:','FT%:','Block%:','Steal%:','3PA/FGA:','A/FGM:','3-Pointers:','2-Pointers:','Free Throws:','Components:','Overall:','Non-conference:','Bench Minutes:','Experience:','Minutes Continuity:','Average Height:']\n",
    "# This creates the difference file\n",
    "# It's the difference between the average teams stats and the result of the game\n",
    "# Result: 0 means the second team won, 1 the first\n",
    "# For each year of interest (previous 4)\n",
    "for final in yearly_avgs :\n",
    "    year = '20' + final.index[0][-2:]\n",
    "    new_data = []\n",
    "    new_sc_data = []\n",
    "    # Go through each team once\n",
    "    for team in final.index :\n",
    "        team_name = team[:-5]\n",
    "        temp_path = path + year + '/' + team_name\n",
    "        # Get average team player stats\n",
    "        team_1 = final.loc[team]\n",
    "        # Get average team stats (scouting report)\n",
    "        sc_data = pd.read_csv(temp_path+'/Scouting_Report_csv')\n",
    "        sc_data = sc_data.drop('Unnamed: 0',axis=1)\n",
    "        sc_data = sc_data.drop(14,axis=0)\n",
    "        sc1_off_data = np.array(sc_data['Offense']).reshape(24)\n",
    "        sc1_def_data = np.array(sc_data['Defense']).reshape(24)\n",
    "        sc1_data = np.hstack((sc1_off_data.astype(float),sc1_def_data.astype(float)))\n",
    "        # Find that team's schedule for the year\n",
    "        for dir_path, dir_name, filename in os.walk(temp_path) :\n",
    "            for name in filename :\n",
    "                if name[-3:] == 'csv' :\n",
    "                    # Read in schedule and filter to just tournament games\n",
    "                    data = pd.read_csv(temp_path+'/'+name)\n",
    "                    data = data.drop('Unnamed: 0',axis=1)\n",
    "                    data = data[data['Conference'] == 'NCAA-T']\n",
    "                    # For each game, ceate a row\n",
    "                    for game in data.index :\n",
    "                        res = data.loc[game]['Result'][0]\n",
    "                        if res == 'L' :\n",
    "                            result = np.array(0).reshape(1)\n",
    "                        else :\n",
    "                            result = np.array(1).reshape(1)\n",
    "                        # This is important if they played more than one game in the tournament\n",
    "                        if sc1_data.shape[0] != 49 :\n",
    "                            sc1_data = np.hstack((sc1_data,result))\n",
    "                        else :\n",
    "                            sc1_data[-1] = result\n",
    "                        # Get opponent name and stats\n",
    "                        opponent = data.loc[game]['Opponent'] + ' ' + team[-4:]\n",
    "                        team_2 = final.loc[opponent]\n",
    "                        # Save into data\n",
    "                        new_info = np.hstack((np.array(team_1-team_2).reshape(19),result))\n",
    "                        if isinstance(new_data,list) :\n",
    "                            new_data = new_info\n",
    "                        else :\n",
    "                            new_data = np.vstack((new_data,new_info))\n",
    "                        # GET SCOUTING REPORT DATA HERE\n",
    "                        n = len(team_name)\n",
    "                        sc_data = pd.read_csv(temp_path[:-n]+opponent[:-5]+'/Scouting_Report_csv')\n",
    "                        sc_data = sc_data.drop('Unnamed: 0',axis=1)\n",
    "                        sc_data = sc_data.drop(14,axis=0)\n",
    "                        sc2_off_data = np.array(sc_data['Offense']).reshape(24)\n",
    "                        sc2_def_data = np.array(sc_data['Defense']).reshape(24)\n",
    "                        sc2_data = np.hstack((sc2_off_data.astype(float),sc2_def_data.astype(float)))\n",
    "                        sc2_data = np.hstack((sc2_data,np.array(0).reshape(1)))\n",
    "                        if isinstance(new_sc_data,list) :\n",
    "                            new_sc_data = sc1_data - sc2_data\n",
    "                        else :\n",
    "                            new_sc_data = np.vstack((new_sc_data,sc1_data-sc2_data))\n",
    "                    # We only need one schedule per team, so break\n",
    "                    break\n",
    "    # Save Data\n",
    "    reorganized = pd.DataFrame(data=new_data,columns=(cols+['Result']))\n",
    "    reorganized.to_csv('Data_2/New_Form_Data_'+year)\n",
    "    reorg_teams = pd.DataFrame(data=new_sc_data)\n",
    "    reorg_teams.to_csv('Data_2/New_Form_Team_'+year)\n",
    "    combo = np.hstack((new_sc_data[:,:-1],new_data))\n",
    "    reorg_combo = pd.DataFrame(data=combo)\n",
    "    reorg_combo.to_csv('Data_2/New_Form_combo_'+year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
